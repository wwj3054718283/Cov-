{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pyCharm\\Anaconda\\lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "import pymysql\n",
    "import hashlib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tencent_data():\n",
    "    \"\"\"\n",
    "    :return: 返回历史数据和当日详细数据\n",
    "    \"\"\"\n",
    "    url_det = 'https://api.inews.qq.com/newsqa/v1/query/inner/publish/modules/list?modules=diseaseh5Shelf'\n",
    "    url_his = \"https://api.inews.qq.com/newsqa/v1/query/inner/publish/modules/list?modules=chinaDayList,chinaDayAddList,nowConfirmStatis,provinceCompare\"\n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36',\n",
    "    }\n",
    "    r_det = requests.get(url_det, headers)\n",
    "    r_his = requests.get(url_his, headers)\n",
    "    res_det = json.loads(r_det.text)  # json字符串转字典\n",
    "    res_his = json.loads(r_his.text)\n",
    "    data_det = res_det['data']['diseaseh5Shelf']\n",
    "    data_his = res_his['data']\n",
    "\n",
    "    history = {}  # 历史数据\n",
    "    for i in data_his[\"chinaDayList\"]:\n",
    "        ds = i[\"y\"]+\".\"+i[\"date\"]\n",
    "        tup = time.strptime(ds, \"%Y.%m.%d\")\n",
    "        ds = time.strftime(\"%Y-%m-%d\", tup)  # 改变时间格式,不然插入数据库会报错，数据库是datetime类型\n",
    "        confirm = i[\"confirm\"]\n",
    "        confirm_now = i[\"nowConfirm\"]\n",
    "        suspect = i[\"suspect\"]\n",
    "        heal = i[\"heal\"]\n",
    "        dead = i[\"dead\"]\n",
    "        history[ds] = {\"confirm\": confirm,\"confirm_now\":confirm_now, \"suspect\": suspect, \"heal\": heal, \"dead\": dead}\n",
    "    for i in data_his[\"chinaDayAddList\"]:\n",
    "        ds = i[\"y\"]+\".\"+i[\"date\"]\n",
    "        tup = time.strptime(ds, \"%Y.%m.%d\")\n",
    "        ds = time.strftime(\"%Y-%m-%d\", tup)\n",
    "        confirm_add = i[\"confirm\"]\n",
    "        suspect_add = i[\"suspect\"]\n",
    "        heal_add = i[\"heal\"]\n",
    "        dead_add = i[\"dead\"]\n",
    "        history[ds].update({\"confirm_add\": confirm_add, \"suspect_add\": suspect_add, \"heal_add\": heal_add, \"dead_add\": dead_add})\n",
    "\n",
    "    details = []  # 当日详细数据\n",
    "    update_time = data_det[\"lastUpdateTime\"]\n",
    "    data_country = data_det[\"areaTree\"]  # list 之前有25个国家,现在只有中国\n",
    "    data_province = data_country[0][\"children\"]  # 中国各省\n",
    "    for pro_infos in data_province:\n",
    "        province = pro_infos[\"name\"]  # 省名\n",
    "        for city_infos in pro_infos[\"children\"]:\n",
    "            city = city_infos[\"name\"] #城市名\n",
    "            confirm = city_infos[\"total\"][\"confirm\"] #l累计确诊\n",
    "            confirm_add = city_infos[\"today\"][\"confirm\"] #新增确诊\n",
    "            confirm_now = city_infos[\"total\"][\"nowConfirm\"] #现有确诊\n",
    "            heal = city_infos[\"total\"][\"heal\"] #累计治愈\n",
    "            dead = city_infos[\"total\"][\"dead\"] #累计死亡\n",
    "            details.append([update_time, province, city, confirm, confirm_add,confirm_now, heal, dead])\n",
    "    return history, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn():\n",
    "    conn = pymysql.connect(host=\"127.0.0.1\",user=\"root\",password=\"wwj520hy\",db=\"covid-19\",charset=\"utf8\")\n",
    "    cursor = conn.cursor()\n",
    "    return conn, cursor\n",
    "def close_conn(conn, cursor):\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取tencent实时数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_details():\n",
    "    \"\"\"\n",
    "    更新 details 表\n",
    "    \"\"\"\n",
    "    cursor = None\n",
    "    conn = None\n",
    "    try:\n",
    "        li = get_tencent_data()[1]\n",
    "        conn, cursor = get_conn()\n",
    "        sql = \"insert into details(update_time,province,city,confirm,confirm_add,confirm_now,heal,dead) \" \\\n",
    "              \"values(%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "        sql_query = 'select %s=(select update_time from details order by id desc limit 1)'\n",
    "        cursor.execute(sql_query,li[0][0])\n",
    "        if not cursor.fetchone()[0]:\n",
    "            print(f\"{time.asctime()}——开始更新——\")\n",
    "            for item in li:\n",
    "                cursor.execute(sql, item)\n",
    "            conn.commit()\n",
    "            print(f\"{time.asctime()}——更新完毕——\")\n",
    "        else:\n",
    "            print(f\"{time.asctime()}——已是最新数据——\")\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        close_conn(conn, cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_history():\n",
    "    \"\"\"\n",
    "    更新历史数据\n",
    "    \"\"\"\n",
    "    cursor = None\n",
    "    conn = None\n",
    "    try:\n",
    "        dic = get_tencent_data()[0]\n",
    "        print(f\"{time.asctime()}——更新历史数据——\")\n",
    "        conn, cursor = get_conn()\n",
    "        sql = \"insert into history values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "        sql_query = \"select confirm from history where ds=%s\"\n",
    "        for k, v in dic.items():\n",
    "            if not cursor.execute(sql_query, k): \n",
    "                cursor.execute(sql, [k, v.get(\"confirm\"), v.get(\"confirm_add\"),v.get(\"confirm_now\"),\n",
    "                                     v.get(\"suspect\"),v.get(\"suspect_add\"), v.get(\"heal\"),\n",
    "                                     v.get(\"heal_add\"),v.get(\"dead\"), v.get(\"dead_add\")])\n",
    "        conn.commit() \n",
    "        print(f\"{time.asctime()}——历史数据更新完毕——\")\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        close_conn(conn, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取中高风险地区数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_risk_area():\n",
    "    \"\"\"\n",
    "    risk_h,risk_m 中高风险地区详细数据\n",
    "    \"\"\"\n",
    "    o = '%.3f' % (time.time() / 1e3)\n",
    "    e = o.replace('.', '')\n",
    "    i = \"23y0ufFl5YxIyGrI8hWRUZmKkvtSjLQA\"\n",
    "    a = \"123456789abcdefg\"\n",
    "    s1 = hashlib.sha256()\n",
    "    s1.update(str(e + i + a + e).encode(\"utf8\"))\n",
    "    s1 = s1.hexdigest().upper()\n",
    "    # 签名2\n",
    "    s2 = hashlib.sha256()\n",
    "    s2.update(str(e + 'fTN2pfuisxTavbTuYVSsNJHetwq5bJvCQkjjtiLM2dCratiA' + e).encode(\"utf8\"))\n",
    "    s2 = s2.hexdigest().upper()\n",
    "    #post请求数据\n",
    "    post_dict = {\n",
    "        'appId': 'NcApplication',\n",
    "        'key': '3C502C97ABDA40D0A60FBEE50FAAD1DA',\n",
    "        'nonceHeader': '123456789abcdefg',\n",
    "        'paasHeader': 'zdww',\n",
    "        'signatureHeader': s1,\n",
    "        'timestampHeader': e\n",
    "    }\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json; charset=utf-8',\n",
    "        'Referer': 'http://bmfw.www.gov.cn/',\n",
    "        'Origin': 'http://bmfw.www.gov.cn',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36',\n",
    "        'x-wif-nonce': 'QkjjtiLM2dCratiA',\n",
    "        'x-wif-paasid': 'smt-application',\n",
    "        'x-wif-signature': s2,\n",
    "        'x-wif-timestamp': e,\n",
    "    }\n",
    "    url = \"http://103.66.32.242:8005/zwfwMovePortal/interface/interfaceJson\"\n",
    "    req = requests.post(url=url, data=json.dumps(post_dict), headers=headers)\n",
    "    resp = req.text\n",
    "    res = json.loads(resp)\n",
    "    # print(res)\n",
    "    utime = res['data']['end_update_time'] #更新时间\n",
    "    hcount = res['data'].get('hcount',0) #高风险地区个数\n",
    "    mcount = res['data'].get('mcount',0) #低风险地区个数\n",
    "    #具体数据\n",
    "    hlist = res['data']['highlist']\n",
    "    mlist = res['data']['middlelist']\n",
    "\n",
    "    risk_h = []\n",
    "    risk_m = []\n",
    "\n",
    "    for hd in hlist:\n",
    "        type = \"高风险\"\n",
    "        province = hd['province']\n",
    "        city = hd['city']\n",
    "        county = hd['county']\n",
    "        area_name = hd['area_name']\n",
    "        communitys = hd['communitys']\n",
    "        for x in communitys:\n",
    "            risk_h.append([utime,province,city,county,x,type])\n",
    "\n",
    "    for md in mlist:\n",
    "        type = \"中风险\"\n",
    "        province = md['province']\n",
    "        city = md['city']\n",
    "        county = md['county']\n",
    "        area_name = md['area_name']\n",
    "        communitys = md['communitys']\n",
    "        for x in communitys:\n",
    "            risk_m.append([utime, province, city, county, x, type])\n",
    "\n",
    "    return risk_h,risk_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_risk_area():\n",
    "    \"\"\"\n",
    "        更新 risk_area 表\n",
    "        \"\"\"\n",
    "    cursor = None\n",
    "    conn = None\n",
    "    try:\n",
    "        risk_h, risk_m = get_risk_area()\n",
    "        conn, cursor = get_conn()\n",
    "        sql = \"insert into risk_area(end_update_time,province,city,county,address,type) values(%s,%s,%s,%s,%s,%s)\"\n",
    "        sql_query = 'select %s=(select end_update_time from risk_area order by id desc limit 1)'\n",
    "        cursor.execute(sql_query, risk_h[0][0])\n",
    "        if not cursor.fetchone()[0]:\n",
    "            print(f\"{time.asctime()}——开始更新最新数据——\")\n",
    "            for item in risk_h:\n",
    "                cursor.execute(sql, item)\n",
    "            for item in risk_m:\n",
    "                cursor.execute(sql, item)\n",
    "            conn.commit()  # 提交事务 update delete insert操作\n",
    "            print(f\"{time.asctime()}——更新最新数据完毕——\")\n",
    "        else:\n",
    "            print(f\"{time.asctime()}——已是最新数据——\")\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        close_conn(conn, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取百度热搜数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baidu_hot():\n",
    "    \"\"\"\n",
    "    百度热搜\n",
    "    \"\"\"\n",
    "    url = \"https://top.baidu.com/board?tab=realtime\"\n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36',\n",
    "    }\n",
    "    res = requests.get(url, headers=headers)\n",
    "    html = res.text\n",
    "    soup = BeautifulSoup(html,features=\"html.parser\")\n",
    "    titles = soup.select(\"div.c-single-text-ellipsis\")\n",
    "    count = soup.select(\"div.hot-index_1Bl1a\")\n",
    "    context = []\n",
    "    for i in range(len(titles)):\n",
    "        t = titles[i].text.strip()\n",
    "        v = count[i].text.strip()\n",
    "        context.append(f\"{t}{v}\".replace('\\n', ''))\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_hotsearch():\n",
    "    \"\"\"\n",
    "    将疫情热搜插入数据库\n",
    "    \"\"\"\n",
    "    cursor = None\n",
    "    conn = None\n",
    "    try:\n",
    "        context = get_baidu_hot()\n",
    "        print(f\"{time.asctime()}——开始更新热搜数据——\")\n",
    "        conn, cursor = get_conn()\n",
    "        sql = \"insert into hotsearch(dt,content) values(%s,%s)\"\n",
    "        ts = time.strftime(\"%Y-%m-%d %X\")\n",
    "        for i in context:\n",
    "            cursor.execute(sql, (ts, i))  # 插入数据\n",
    "        conn.commit()  # 提交事务保存数据\n",
    "        print(f\"{time.asctime()}——数据更新完毕——\")\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        close_conn(conn, cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  7 13:00:38 2022——开始更新——\n",
      "Mon Mar  7 13:00:38 2022——更新完毕——\n"
     ]
    }
   ],
   "source": [
    "update_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  7 13:00:38 2022——更新历史数据——\n",
      "Mon Mar  7 13:00:38 2022——历史数据更新完毕——\n"
     ]
    }
   ],
   "source": [
    "update_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  7 13:00:39 2022——开始更新最新数据——\n",
      "Mon Mar  7 13:00:39 2022——更新最新数据完毕——\n"
     ]
    }
   ],
   "source": [
    "update_risk_area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  7 13:00:39 2022——开始更新热搜数据——\n",
      "Mon Mar  7 13:00:39 2022——数据更新完毕——\n"
     ]
    }
   ],
   "source": [
    "update_hotsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url=\"https://api.inews.qq.com/newsqa/v1/query/inner/publish/modules/list?\"\n",
    "url_details = base_url+\"modules=diseaseh5Shelf\"\n",
    "url_history = base_url+\"modules=chinaDayList,chinaDayAddList,nowConfirmStatis,provinceCompare\"\n",
    "url_riskarea = \"http://103.66.32.242:8005/zwfwMovePortal/interface/interfaceJson\"\n",
    "url_hotsearch = \"https://top.baidu.com/board?tab=realtime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5276"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = get_tencent_data()[1]\n",
    "conn, cursor = get_conn()\n",
    "sql_query = 'select * from details'\n",
    "cursor.execute(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
